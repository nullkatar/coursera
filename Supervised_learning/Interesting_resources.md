## Ресурсы по материалам 1 недели:

- В заданиях прошедшей недели вам пришлось рисовать много графиков и отправлять их на проверку коллегам — наверняка Вы заметили, что это не так уж просто. [Вот](http://bit.ly/2a28Ni7)
- Машинное обучение часто противопоставляют классическому математическому моделированию. [Тут](http://bit.ly/29OR5Kw) вы можете прочитать о том, что это такое и в чём заключаются отличия.
- Градиентный спуск на пальцах разобран [вот здесь.](https://nplus1.ru/material/2016/09/06/mistakesflow?utm_source=telegram&utm_campaign=autumn)

## Ресурсы по материалам 2 недели:

- Под переобучением можно понимать не только ситуации, в которых модель слишком сильно подгоняется под данные. [Статья](http://bit.ly/2a3H8Mh)
- Поначалу метрика AUC-ROC может казаться очень нелогичной, но на самом деле у неё есть много интерпретаций. [Вот](http://bit.ly/2aaQecF)

## Ресурсы по материалам 3 недели:

- Как вы узнали из прошедшего модуля, в логистической регрессии оптимизируется метрика log-loss. В [статье](http://bit.ly/29IBvRR) можно чуть больше узнать о том, откуда она берётся.
- Некоторые практические рекомендации по работе с линейными моделями можно найти [тут](http://bit.ly/29VpnQ0).

## Ресурсы по материалам 4,5 недели:

- Интересную визуализацию обучения и применения решающих деревьев можно найти [тут](http://bit.ly/29Q9cDg).
- Машинное обучение можно применять для решения достаточно неожиданных задач — например, определять пол по имени. [Подробности](http://bit.ly/2a6iXMX)
- Если вам нравятся красивые картинки про [работу композиций](http://bit.ly/29Q4JOo).
- А в [этой статье](http://bit.ly/2aaWVLN) можно прочитать о том, как настраивать параметры градиентного бустинга в sklearn.
- Посмотреть на то, как выглядят разделяющие поверхности у нейросетей при разных значениях гиперпараметров, можно [тут](http://bit.ly/2a6mTNG)
